{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ds8XS0BTnPgg",
        "iTTlh0lKp5Ne"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDotapoDm75y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,Conv2D\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.keras import metrics\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.callbacks import Callback\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "regd-Um8nKLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "Ds8XS0BTnPgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/ifood-2019-fgvc6.zip"
      ],
      "metadata": {
        "id": "9bD_6U5-nL_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 251\n",
        "width, height = 224, 224\n",
        "train_dir = '/content/ifood-2019-fgvc6/organized_train_set'\n",
        "val_dir = '/content/ifood-2019-fgvc6/organized_val_set'\n",
        "test_dir = '/content/ifood-2019-fgvc6/test_set'\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "ReL2uPdhnOJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = '/content/drive/MyDrive/train_incorrect.csv'\n",
        "\n",
        "incorrect_images_df = pd.read_csv(csv_path, header=None)\n",
        "incorrect_images = incorrect_images_df[0].tolist()  # Access the first (and only) column\n",
        "\n",
        "for root, dirs, files in os.walk(train_dir):  # Traverse through all class subdirectories\n",
        "    for img_file in incorrect_images:\n",
        "        img_path = os.path.join(root, img_file)\n",
        "        if os.path.exists(img_path):\n",
        "            os.remove(img_path)\n",
        "            print(f\"Removed {img_file} from {root}\")\n",
        "        #else:\n",
        "           # print(f\"{img_file} not found in {root}\")"
      ],
      "metadata": {
        "id": "Yt0SKognncw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    validation_split=0.3,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "metadata": {
        "id": "mcpiueEjniG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(width, height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        ")\n",
        "\n",
        "val_set = validation_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(width, height),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    class_mode='categorical',\n",
        ")"
      ],
      "metadata": {
        "id": "qxYF8Ch0nkfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all class directories\n",
        "class_dirs = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
        "\n",
        "# Count the number of images in each class directory\n",
        "class_counts = [len(os.listdir(os.path.join(train_dir, cls))) for cls in class_dirs]\n",
        "\n",
        "# Plot the frequency of image counts using a histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(class_counts, bins=20, color='skyblue', edgecolor='black')\n",
        "\n",
        "plt.title('Frequency Distribution of Image Counts per Class', fontsize=16)\n",
        "plt.xlabel('Number of Images per Class', fontsize=12)\n",
        "plt.ylabel('Frequency of Classes', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the frequency chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RBsC0GVZnqz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_labels = train_set.classes  # Labels for each image in the training set\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                  classes=np.unique(class_labels),\n",
        "                                                  y=class_labels)\n",
        "\n",
        "# Keras requires dict format\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "print(\"Class Weights:\", class_weights_dict)"
      ],
      "metadata": {
        "id": "N4AGHML8nwlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Callbacks"
      ],
      "metadata": {
        "id": "LSHXJCddn0cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/Pre-Trained-Tests'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Get the current timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Callbacks\n",
        "Callbacks = [\n",
        "    ModelCheckpoint(filepath=os.path.join(checkpoint_dir, f'DenseNet201_Best_{timestamp}.keras'),\n",
        "                    save_best_only=True,\n",
        "                    monitor='val_loss',\n",
        "                    mode='min',\n",
        "                    save_weights_only=False,\n",
        "                    verbose=1),  # Save the best model based on validation loss\n",
        "    EarlyStopping(monitor='val_loss',\n",
        "                  patience=10,  # Stop training after 10 epochs without improvement\n",
        "                  mode='min',\n",
        "                  verbose=1,\n",
        "                  restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss',\n",
        "                      factor=0.2,  # Reduce learning rate by 20%\n",
        "                      patience=3,  # Reduce if no improvement after 3 epochs\n",
        "                      mode='min',\n",
        "                      verbose=1),\n",
        "]"
      ],
      "metadata": {
        "id": "TiKw4zIln3Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveHistory(Callback):\n",
        "\n",
        "    def __init__(self, save_path):\n",
        "\n",
        "        super(SaveHistory, self).__init__()\n",
        "\n",
        "        self.save_path = save_path\n",
        "\n",
        "        # Load history if exists\n",
        "        if os.path.exists(self.save_path):\n",
        "\n",
        "            with open(self.save_path, 'rb') as f:\n",
        "                self.history = pickle.load(f)\n",
        "\n",
        "        else:\n",
        "            self.history = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': [], 'precision': [], 'val_precision': [], 'recall': [], 'val_recall': []}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Append new logs to the existing history\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "        self.history['val_accuracy'].append(logs.get('val_accuracy'))\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['val_loss'].append(logs.get('val_loss'))\n",
        "        self.history['precision'].append(logs.get('precision'))\n",
        "        self.history['val_precision'].append(logs.get('val_precision'))\n",
        "        self.history['recall'].append(logs.get('recall'))\n",
        "        self.history['val_recall'].append(logs.get('val_recall'))\n",
        "\n",
        "        # Create directory if it doesn't exist\n",
        "        os.makedirs(os.path.dirname(self.save_path), exist_ok=True)\n",
        "\n",
        "        # Save history to a file\n",
        "        with open(self.save_path, 'wb') as f:\n",
        "            pickle.dump(self.history, f)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} history saved to {self.save_path}\")\n",
        "\n",
        "# Create a unique filename with a timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "history_save_path = f'/content/drive/MyDrive/Pre-Trained_Tests/DenseNet201_Training_{timestamp}.pkl'\n",
        "\n",
        "# Create the callback\n",
        "history_callback = SaveHistory(save_path=history_save_path)\n"
      ],
      "metadata": {
        "id": "TWLScDy1oY5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DenseNet201 Model Testing"
      ],
      "metadata": {
        "id": "3gx5yj0Kow_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False,input_shape=(width,width,3))\n",
        "for layer in resnet.layers[:150]:\n",
        "    layer.trainable=False"
      ],
      "metadata": {
        "id": "3fW_8n2YpCsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(300,activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=resnet.input, outputs=output)"
      ],
      "metadata": {
        "id": "KK08XfebpWug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "tBAFV-b8q-Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])\n",
        "\n",
        "history = model.fit(train_set,\n",
        "                      validation_data=val_set,\n",
        "                      epochs=20,\n",
        "                      verbose=1,\n",
        "                      class_weight=class_weights_dict,\n",
        "                      callbacks=[Callbacks, history_callback])"
      ],
      "metadata": {
        "id": "4oDXD9q6pXSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/')\n",
        "\n",
        "history = loaded_model.fit(train_set,\n",
        "                      validation_data=val_set,\n",
        "                      epochs=30,\n",
        "                      verbose=1,\n",
        "                      class_weight=class_weights_dict,\n",
        "                      callbacks=[Callbacks, history_callback])\n",
        "'''"
      ],
      "metadata": {
        "id": "O5xJoW2XpnYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Results Evalutation"
      ],
      "metadata": {
        "id": "iTTlh0lKp5Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/Pre-Trained_Tests/DenseNet201_Best_{}.keras')\n",
        "y_true = val_set.classes\n",
        "prediction = loaded_model.predict(val_set)\n",
        "y_pred = np.argmax(prediction, axis=1)\n",
        "\n",
        "label_map = {}\n",
        "with open('/content/ifood-2019-fgvc6/class_list.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        numerical_label, actual_label = line.strip().split()\n",
        "        label_map[int(numerical_label)] = actual_label\n",
        "\n",
        "y_true_mapped = [label_map[label] for label in y_true]\n",
        "y_pred_mapped = [label_map[label] for label in y_pred]\n",
        "\n",
        "\n",
        "print(\"Sample of y_true:\", y_true_mapped[:10])\n",
        "print(\"Sample of y_pred:\", y_pred_mapped[:10])\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true_mapped, y_pred_mapped, zero_division=1)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "S1xxnmGrp9lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = loaded_model.evaluate(val_set)\n",
        "print(\"\\nTest Loss:\", result[0])\n",
        "print(\"Test Accuracy:\", result[1])\n",
        "print(\"Test Precision:\", result[2])\n",
        "print(\"Test Recall:\", result[3])"
      ],
      "metadata": {
        "id": "vTwziiEuqO35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = list(val_set.class_indices.keys())\n",
        "\n",
        "test_images, test_labels = next(val_set)\n",
        "predictions = loaded_model.predict(test_images)\n",
        "\n",
        "for i in range(20):\n",
        "    predicted_label_index = np.argmax(predictions[i])\n",
        "    predicted_label = class_labels[predicted_label_index]\n",
        "    true_label_index = np.argmax(test_labels[i])\n",
        "    true_label = class_labels[true_label_index]\n",
        "\n",
        "    plt.figure(figsize=(2,2))\n",
        "    plt.imshow(test_images[i])\n",
        "    plt.title(f\"Predicted Label: {predicted_label}\\nTrue Label: {true_label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OqgpLwnlqWO0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}